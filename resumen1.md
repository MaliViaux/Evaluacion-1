# PEP1

Created: May 12, 2025 11:23 AM
Class: INFERENCIAL

| **MÃ©todo / Prueba** | **Â¿Para quÃ© sirve?** | **Condiciones** |
| --- | --- | --- |
| **Prueba Z para una muestra** | Contrastar si la media poblacional es igual a un valor conocido | - Observaciones independientes  - Muestra â‰¥ 30 o se conoce Ïƒ  - PoblaciÃ³n con distribuciÃ³n normal |
| **Prueba t para una muestra** | Igual que la Z, pero sin conocer Ïƒ (para n < 30) | - Observaciones independientes  - PoblaciÃ³n con distribuciÃ³n normal |
| **Prueba t para dos muestras independientes** | Comparar medias de dos poblaciones independientes | - Muestras independientes  - Normalidad en cada grupo  - Igualdad de varianzas (si `var.equal=TRUE`) |
| **Prueba t para muestras pareadas** | Comparar medias de dos tratamientos en los mismos sujetos o pares naturales | - Observaciones apareadas  - DistribuciÃ³n normal de las diferencias |

### ğŸ”¹ PRUEBA Z PARA UNA MUESTRA

**Â¿Para quÃ© sirve?**

Contrasta la hipÃ³tesis sobre si la media poblacional es igual a un valor hipotÃ©tico, cuando se conoce la desviaciÃ³n estÃ¡ndar de la poblaciÃ³n o el tamaÃ±o muestral es grande (n â‰¥ 30).

**Ejemplos de estudios:**

1. Â¿Es la utilidad promedio de las empresas apoyadas por una incubadora igual a 20 millones?
2. Â¿El tiempo promedio de ejecuciÃ³n de un algoritmo supera los 60 segundos?

**Condiciones:**

- Observaciones independientes.
- PoblaciÃ³n con distribuciÃ³n normal.
- TamaÃ±o muestral â‰¥ 30 o se conoce Ïƒ.

**HipÃ³tesis:**

- Hâ‚€: Î¼ = Î¼â‚€
- Hâ‚: Î¼ â‰  Î¼â‚€ (o Î¼ < Î¼â‚€, Î¼ > Î¼â‚€, segÃºn el caso)

**FunciÃ³n en R:**

z.test(x, mu=mu_hipotetico, stdev=desv_est, conf.level=0.95)

**InterpretaciÃ³n:** El valor p indica si hay evidencia suficiente para rechazar Hâ‚€ al nivel Î±.

### ğŸ”¹ PRUEBA t DE STUDENT PARA UNA MUESTRA

**Â¿Para quÃ© sirve?**

Igual que la prueba Z, pero cuando la desviaciÃ³n estÃ¡ndar poblacional no se conoce y el tamaÃ±o muestral es pequeÃ±o (n < 30).

**Ejemplos de estudios:**

1. Â¿El tiempo medio de respuesta de un sistema es menor a 500 ms?
2. Â¿La concentraciÃ³n media de un compuesto quÃ­mico es 8 mg/l?

**Condiciones:**

- Observaciones independientes.
- PoblaciÃ³n con distribuciÃ³n normal.

**HipÃ³tesis:**

- Hâ‚€: Î¼ = Î¼â‚€
- Hâ‚: Î¼ â‰  Î¼â‚€

**FunciÃ³n en R:**

```r
r
CopyEdit
t.test(x, mu = mu_hipotetico, alternative = "two.sided")

```

**InterpretaciÃ³n:** Si el valor p < Î±, se rechaza Hâ‚€.

### ğŸ”¹ PRUEBA t PARA DOS MUESTRAS INDEPENDIENTES

**Â¿Para quÃ© sirve?**

Compara las medias de dos poblaciones independientes para evaluar si existe diferencia significativa.

**Ejemplos de estudios:**

1. Â¿Las vacunas A y B generan igual concentraciÃ³n media de anticuerpos?
2. Â¿Dos mÃ©todos de enseÃ±anza producen igual rendimiento acadÃ©mico?

**Condiciones:**

- Muestras independientes.
- Cada muestra cumple condiciones de uso de la t (normalidad, independencia).

**HipÃ³tesis:**

- Hâ‚€: Î¼â‚ = Î¼â‚‚
- Hâ‚: Î¼â‚ â‰  Î¼â‚‚

**FunciÃ³n en R:**

```r
r
CopyEdit
t.test(x1, x2, var.equal = FALSE)

```

**InterpretaciÃ³n:** Si p < Î±, se concluye diferencia significativa entre medias.

---

<aside>
ğŸ’¡

si Î± = 0.05, la confianza es 0.95 (95%).
Î± = 1 - confianza

</aside>

### ğŸ”¹ PRUEBA t PARA DOS MUESTRAS PAREADAS

**Â¿Para quÃ© sirve?**

Contrasta medias de dos tratamientos aplicados a los mismos sujetos (antes/despuÃ©s, o con pares naturales).

**Ejemplos de estudios:**

1. Â¿Un curso mejora el puntaje en un test antes y despuÃ©s de tomarlo?
2. Â¿La dieta baja el colesterol tras 6 semanas?

**Condiciones:**

- Pares de datos correspondientes a los mismos sujetos.
- Diferencias siguen distribuciÃ³n normal.

**HipÃ³tesis:**

- Hâ‚€: Î¼_d = 0 (promedio de las diferencias es cero)
- Hâ‚: Î¼_d â‰  0

**FunciÃ³n en R:**

```r
r
CopyEdit
t.test(x, y, paired = TRUE)

```

**InterpretaciÃ³n:** Si p < Î±, existe evidencia de cambio entre condiciones.

---

| **MÃ©todo / Prueba** | **Â¿Para quÃ© sirve?** | **Condiciones** |
| --- | --- | --- |
| **Wald para una proporciÃ³n** | Evaluar si una proporciÃ³n poblacional es igual a un valor especÃ­fico | - Observaciones independientes   - npâ‰¥10np â‰¥ 10 y n(1âˆ’p)â‰¥10n(1-p) â‰¥ 10 |
| **Wald para dos proporciones** | Comparar si dos proporciones poblacionales son iguales | - Muestras independientes   - Ambas proporciones cumplen condiciÃ³n Ã©xito-fracaso |
| **Wilson para una proporciÃ³n** | Estimar un intervalo de confianza preciso para una proporciÃ³n | - Observaciones independientes   - npâ‰¥10np â‰¥ 10 y n(1âˆ’p)â‰¥10n(1-p) â‰¥ 10 |
| **Wilson para dos proporciones** | Comparar dos proporciones con mejor precisiÃ³n que Wald | - Muestras independientes   - Cada grupo cumple condiciÃ³n Ã©xito-fracaso |

### ğŸ”¹ MÃ©todo de Wald para una proporciÃ³n

**Â¿Para quÃ© sirve?**

Permite contrastar si una proporciÃ³n poblacional es igual a un valor especÃ­fico, asumiendo una aproximaciÃ³n normal.

**Ejemplos de estudios:**

1. Â¿QuÃ© proporciÃ³n de algoritmos se ejecutan en menos de 25 segundos?
2. Â¿MÃ¡s del 70% de los clientes estÃ¡n satisfechos con un producto?

**Condiciones:**

- Observaciones independientes.
- CondiciÃ³n Ã©xito-fracaso: npâ‰¥10np â‰¥ 10npâ‰¥10 y n(1âˆ’p)â‰¥10n(1-p) â‰¥ 10n(1âˆ’p)â‰¥10.

**HipÃ³tesis:**

- Hâ‚€: p=p0p = pâ‚€p=p0
- Hâ‚: p<p0p < pâ‚€p<p0, p>p0p > pâ‚€p>p0 o pâ‰ p0p â‰  pâ‚€pî€ =p0

**FunciÃ³n en R:**

No existe una funciÃ³n directa; se calcula manualmente.

```r
r
CopyEdit
Z <- (phat - p0) / sqrt(p0 * (1 - p0) / n)
p <- pnorm(Z, lower.tail = FALSE)

```

**InterpretaciÃ³n:** Si p < Î±, se rechaza Hâ‚€.

---

### ğŸ”¹ MÃ©todo de Wald para dos proporciones

**Â¿Para quÃ© sirve?**

Compara si dos proporciones poblacionales son iguales.

**Ejemplos de estudios:**

1. Â¿La tasa de reprobaciÃ³n difiere entre hombres y mujeres en un curso?
2. Â¿Dos campaÃ±as publicitarias producen igual proporciÃ³n de compras?

**Condiciones:**

- Independencia entre las muestras.
- Cada proporciÃ³n por separado cumple la condiciÃ³n de Ã©xito-fracaso.

**HipÃ³tesis:**

- Hâ‚€: p1=p2p_1 = p_2p1=p2
- Hâ‚: p1â‰ p2p_1 â‰  p_2p1î€ =p2

**FunciÃ³n en R:**

Se puede calcular manualmente o con `prop.test()`.

```r
r
CopyEdit
Z <- (phat1 - phat2) / sqrt(p*(1-p)*(1/n1 + 1/n2))  # con p agrupada

```

---

### ğŸ”¹ MÃ©todo de Wilson para una proporciÃ³n

**Â¿Para quÃ© sirve?**

Proporciona intervalos de confianza mÃ¡s precisos para una proporciÃ³n que Wald, especialmente con muestras pequeÃ±as.

**Ejemplos de estudios:**

1. Â¿MÃ¡s del 70% de productos pasan el control de calidad?
2. Â¿Una vacuna es efectiva en al menos 80% de los casos?

**Condiciones:**

- Igual que Wald.

**HipÃ³tesis:**

- Hâ‚€: p=p0p = pâ‚€p=p0
- Hâ‚: pâ‰ p0p â‰  pâ‚€pî€ =p0

**FunciÃ³n en R:**

```r
r
CopyEdit
prop.test(x = Ã©xitos, n = n, p = p0, alternative = "greater", conf.level = 0.95)

```

---

### ğŸ”¹ MÃ©todo de Wilson para dos proporciones

**Â¿Para quÃ© sirve?**

Contrasta si dos proporciones son iguales, con mejor rendimiento en muestras pequeÃ±as.

**Ejemplos de estudios:**

1. Â¿Hombres y mujeres se resfrÃ­an igual tras tomar un tÃ³nico?
2. Â¿Hay diferencia en votantes a favor de una ley entre dos regiones?

**Condiciones:**

- Muestras independientes.
- CondiciÃ³n Ã©xito-fracaso para cada grupo.

**HipÃ³tesis:**

- Hâ‚€: p1=p2p_1 = p_2p1=p2
- Hâ‚: p1â‰ p2p_1 â‰  p_2p1î€ =p2

**FunciÃ³n en R:**

```r
r
CopyEdit
prop.test(x = c(Ã©xitos1, Ã©xitos2), n = c(n1, n2), alternative = "two.sided")

```

### ğŸ”¹ **Poder estadÃ­stico (1 - Î²)**

**Â¿Para quÃ© sirve?**

EvalÃºa la probabilidad de detectar un efecto real (es decir, rechazar correctamente una hipÃ³tesis nula falsa). Se utiliza para:

- DiseÃ±ar estudios con tamaÃ±o muestral suficiente.
- Interpretar si una prueba no significativa puede deberse a falta de poder y no ausencia de efecto.

### **Ejemplos de estudios y preguntas de investigaciÃ³n**

1. **Ejemplo 1:**
    - *Estudio:* Evaluar si un nuevo algoritmo reduce el tiempo de ejecuciÃ³n en problemas complejos.
    - *Pregunta:* Â¿El nuevo algoritmo tarda, en promedio, menos de 60 segundos para resolver una instancia de mochila con 20.000 objetos?
2. **Ejemplo 2:**
    - *Estudio:* Determinar si una pÃ­ldora mejora el promedio de notas finales.
    - *Pregunta:* Â¿El consumo diario de la pÃ­ldora mejora en al menos 0.5 dÃ©cimas el promedio de egreso?

### **Condiciones**

- Definir correctamente las hipÃ³tesis.
- Conocer la desviaciÃ³n estÃ¡ndar y tamaÃ±o muestral.
- Tener claro el nivel de significaciÃ³n Î± y la magnitud del efecto esperado (Î´).

### **HipÃ³tesis: ejemplo para prueba Z**

- **HipÃ³tesis nula (Hâ‚€):** La media del tiempo de ejecuciÃ³n del algoritmo es 60 segundos.
    
    H0:Î¼=60H_0: \mu = 60H0:Î¼=60
    
- **HipÃ³tesis alternativa (Hâ‚):** La media del tiempo de ejecuciÃ³n es distinta de 60 segundos.
    
    HA:Î¼â‰ 60H_A: \mu \ne 60HA:Î¼î€ =60
    

### **FunciÃ³n en R para calcular poder (usando `pwr`):**

Para prueba Z bilateral:

```r
r
CopyEdit
library(pwr)
pwr.norm.test(n = 36, d = delta / sd, sig.level = 0.05, alternative = "two.sided")

```

- `d = delta / sd`: tamaÃ±o del efecto (diferencia esperada / desviaciÃ³n estÃ¡ndar).
- `n`: tamaÃ±o muestral.
- `sig.level`: nivel de significaciÃ³n Î±.
- `alternative`: tipo de prueba ("two.sided", "less", "greater").

**InterpretaciÃ³n:**

El resultado indica la **potencia** (entre 0 y 1). Un valor â‰¥ 0.80 se considera adecuado para detectar el efecto.

| **MÃ©todo / Prueba** | **Â¿Para quÃ© sirve?** | **Condiciones** |
| --- | --- | --- |
| **Prueba exacta de Fisher** | Evaluar si existe asociaciÃ³n entre dos variables categÃ³ricas binarias (2Ã—2) | - Variables dicotÃ³micas (2 niveles)  - Observaciones independientes  - Muestras pequeÃ±as o con celdas con frecuencias â‰¤ 5 |

### ğŸ”¹ **Prueba exacta de Fisher**

**Â¿Para quÃ© sirve?**

EvalÃºa si hay **asociaciÃ³n entre dos variables categÃ³ricas binarias** (dicotÃ³micas), especialmente con **muestras pequeÃ±as** o cuando las frecuencias observadas son muy bajas (incluso cero).

---

### **Ejemplos de estudios y preguntas de investigaciÃ³n**

1. **Estudio:** Comparar la efectividad de dos vacunas contra mordeduras de vampiro.
    - *Pregunta:* Â¿El tipo de vacuna recibida (Argh vs Grrr) influye en si una persona se convierte en vampiro?
2. **Estudio:** Determinar si hay relaciÃ³n entre el gÃ©nero y aprobar un curso de estadÃ­stica.
    - *Pregunta:* Â¿Existe asociaciÃ³n entre el gÃ©nero del estudiante y su resultado (aprobado/reprobado)?

---

### **Condiciones**

- Dos variables categÃ³ricas **binarias** (sÃ­/no, Ã©xito/fracaso, etc.).
- Observaciones **independientes**.
- TamaÃ±o muestral pequeÃ±o o alguna celda con frecuencias < 5 o igual a 0.
- Las sumas marginales (totales por fila y columna) estÃ¡n fijas.

---

### **HipÃ³tesis**

- **HipÃ³tesis nula (Hâ‚€):** Las variables son independientes (no hay asociaciÃ³n).
    
    *Ejemplo:* El resultado de la mordida (vampiro/humano) no depende de la vacuna recibida.
    
- **HipÃ³tesis alternativa (Hâ‚):** Las variables estÃ¡n asociadas.
    
    *Ejemplo:* El resultado de la mordida depende de la vacuna recibida.
    

---

### **FunciÃ³n en R**

```r
r
CopyEdit
fisher.test(matrix)

```

**Ejemplo en R:**

```r
r
CopyEdit
# Matriz de 2x2: filas = resultado, columnas = vacuna
tabla <- matrix(c(0, 5, 6, 6), nrow = 2, byrow = TRUE)
fisher.test(tabla)

```

**InterpretaciÃ³n del resultado:**

- El valor `p-value` indica si se rechaza Hâ‚€.
- Si `p < Î±`, se concluye que **hay asociaciÃ³n significativa** entre las dos variables.
- Si `p â‰¥ Î±`, no se rechaza Hâ‚€; **no hay evidencia de asociaciÃ³n**.

### ğŸ”¹ **Prueba de McNemar** (CapÃ­tulo 8)

**Â¿Para quÃ© sirve?**

Detectar cambios en proporciones en estudios con datos pareados dicotÃ³micos (pre/post o pruebas repetidas sobre el mismo grupo).

**Ejemplos:**

1. Â¿CambiÃ³ el diagnÃ³stico de una enfermedad despuÃ©s de aplicar un nuevo test?
2. Â¿MejorÃ³ el rendimiento tras un curso de capacitaciÃ³n?

**Condiciones:**

- Dos medidas dicotÃ³micas (sÃ­/no) en los mismos sujetos.
- Datos apareados.
- InterÃ©s en discordancias.

**HipÃ³tesis:**

- Hâ‚€: No hay cambio significativo (proporciones iguales).
- Hâ‚: SÃ­ hay cambio significativo.

**FunciÃ³n en R:**

```r
r
CopyEdit
mcnemar.test(tabla, correct = FALSE)
```

### ğŸ”¹ **Prueba Q de Cochran** (CapÃ­tulo 8)

**Â¿Para quÃ© sirve?**

ExtensiÃ³n de McNemar a mÃ¡s de dos tratamientos (medidas dicotÃ³micas en mÃºltiples condiciones).

**Ejemplos:**

1. Â¿Hay diferencia en el Ã©xito entre tres algoritmos de optimizaciÃ³n?
2. Â¿Distintas vacunas generan igual proporciÃ³n de inmunidad?

**Condiciones:**

- Variable respuesta dicotÃ³mica.
- Medidas repetidas en tres o mÃ¡s condiciones.
- Datos pareados.

**HipÃ³tesis:**

- Hâ‚€: Proporciones iguales en todas las condiciones.
- Hâ‚: Al menos una difiere.

**FunciÃ³n en R:**

No base, pero implementable con paquetes como `rcompanion` o `DescTools`.

---

### ğŸ”¹ **Wilcoxon Rank Sum (Mann-Whitney U)** (CapÃ­tulo 11)

**Â¿Para quÃ© sirve?**

Comparar si dos muestras independientes tienen igual tendencia central (mediana).

**Ejemplos:**

1. Â¿Dos interfaces de software tienen igual usabilidad percibida?
2. Â¿Los tiempos de respuesta difieren entre dos servidores?

**Condiciones:**

- Escala ordinal o superior.
- Muestras independientes.

**HipÃ³tesis:**

- Hâ‚€: No hay diferencia de ubicaciÃ³n (medianas iguales).
- Hâ‚: Hay diferencia.

**FunciÃ³n en R:**

```r
r
CopyEdit
wilcox.test(x, y, paired = FALSE)

```

### ğŸ”¹ **ANOVA de una vÃ­a (muestras independientes)**

- **ANOVA es un procedimiento Ã³mnibus**, lo que implica que **si se encuentra diferencia significativa**, se **requiere un anÃ¡lisis post-hoc** para determinar **dÃ³nde** estÃ¡n las diferencias (entre quÃ© pares de grupos).
- El anÃ¡lisis post-hoc mÃ¡s utilizado y sugerido es **Tukey HSD** (honestly significant difference), pero el desarrollo tÃ©cnico de este mÃ©todo **se deja implÃ­cito** y **no se profundiza** en el capÃ­tulo.

**Â¿Para quÃ© sirve?**

Contrasta si existen diferencias significativas entre las medias de **tres o mÃ¡s grupos independientes**. Es una generalizaciÃ³n de la prueba t para mÃ¡s de dos grupos.

---

### **Ejemplos de estudios y preguntas de investigaciÃ³n**

1. **Estudio:** Evaluar si tres algoritmos distintos difieren en su tiempo promedio de ejecuciÃ³n.
    - *Pregunta:* Â¿Existe diferencia en los tiempos promedio requeridos por los algoritmos A, B y C para resolver el mismo problema?
2. **Estudio:** Comparar la efectividad de tres mÃ©todos de enseÃ±anza.
    - *Pregunta:* Â¿Hay diferencia significativa en el rendimiento acadÃ©mico promedio entre los estudiantes que usaron los mÃ©todos 1, 2 y 3?

---

### **Condiciones**

- La variable dependiente se mide en escala de intervalos iguales (o de razÃ³n).
- Muestras independientes y aleatorias.
- Normalidad en cada grupo (comprobada con grÃ¡ficos Q-Q o prueba de Shapiro-Wilk).
- Homogeneidad de varianzas entre los grupos (por ejemplo, ratio mÃ¡x/mÃ­n â‰¤ 1.5).

---

### **HipÃ³tesis**

- **HipÃ³tesis nula (Hâ‚€):** Las medias de los grupos son iguales.
    
    H0:Î¼1=Î¼2=Î¼3=â‹¯=Î¼kH_0: \mu_1 = \mu_2 = \mu_3 = \dots = \mu_kH0:Î¼1=Î¼2=Î¼3=â‹¯=Î¼k
    
- **HipÃ³tesis alternativa (Hâ‚):** Al menos una media difiere de las otras.
    
    HA:âˆƒÂ i,jÂ âˆ£Â Î¼iâ‰ Î¼jH_A: \exists\ i, j\ |\ \mu_i \ne \mu_jHA:âˆƒÂ i,jÂ âˆ£Â Î¼iî€ =Î¼j
    

---

### **FunciÃ³n en R**

```r
r
CopyEdit
aov(resultado ~ grupo, data = datos)
summary(modelo)

```

**Ejemplo en R:**

```r
r
CopyEdit
datos <- data.frame(
  tiempo = c(23,19,25,23,20, 26,24,28,23,29, 19,24,20,21,17),
  algoritmo = factor(rep(c("A", "B", "C"), each = 5))
)

modelo <- aov(tiempo ~ algoritmo, data = datos)
summary(modelo)

```

**InterpretaciÃ³n del resultado:**

- Si el valor `Pr(>F)` del resumen es menor que Î±, se **rechaza Hâ‚€**.
- Se concluye que **al menos un grupo difiere significativamente en su media**.
- Si se rechaza Hâ‚€, se puede aplicar un **post-hoc** (TukeyHSD) para identificar entre quÃ© grupos estÃ¡n las diferencias:
    
    ```r
    r
    CopyEdit
    TukeyHSD(modelo)
    
    ```
    

### ğŸ”¹ **ANOVA de una vÃ­a para muestras correlacionadas (medidas repetidas)**

**Â¿Para quÃ© sirve?**

Permite contrastar si existen diferencias significativas entre tres o mÃ¡s tratamientos aplicados a los mismos sujetos o unidades (diseÃ±o de medidas repetidas o bloques aleatorios). Controla la variabilidad entre individuos.

---

### **Ejemplos de estudios y preguntas de investigaciÃ³n**

1. **Estudio:** Comparar el rendimiento de 4 algoritmos aplicados a las mismas instancias.
    - *Pregunta:* Â¿Existe diferencia significativa entre los tiempos de ejecuciÃ³n promedio de Quicksort, Bubblesort, Mergesort y Radixsort al ordenar los mismos arreglos?
2. **Estudio:** Medir el avance acadÃ©mico de estudiantes en distintos niveles escolares.
    - *Pregunta:* Â¿Hay diferencia significativa en la estatura promedio de estudiantes al comenzar 7Âº bÃ¡sico, 8Âº bÃ¡sico y 1Âº medio?

---

### **Condiciones**

- Variable dependiente con escala de intervalos iguales (o razÃ³n).
- Observaciones independientes dentro de cada nivel.
- SuposiciÃ³n razonable de normalidad para las mediciones.
- Esfericidad: varianzas de las diferencias entre todos los pares de niveles deben ser iguales.

---

### **HipÃ³tesis**

- **HipÃ³tesis nula (Hâ‚€):** Las medias de los tratamientos (medidas repetidas) son iguales.
    
    H0:Î¼1=Î¼2=Î¼3=â‹¯=Î¼kH_0: \mu_1 = \mu_2 = \mu_3 = \dots = \mu_kH0:Î¼1=Î¼2=Î¼3=â‹¯=Î¼k
    
- **HipÃ³tesis alternativa (Hâ‚):** Al menos una media difiere.
    
    HA:âˆƒÂ i,jÂ âˆ£Â Î¼iâ‰ Î¼jH_A: \exists\ i, j\ |\ \mu_i \ne \mu_jHA:âˆƒÂ i,jÂ âˆ£Â Î¼iî€ =Î¼j
    

---

### **FunciÃ³n en R**

Usando el paquete `ez` con datos en formato largo:

```r
r
CopyEdit
library(ez)
ezANOVA(data = datos_largos, dv = .(variable_dependiente),
        wid = .(id_sujeto), within = .(condicion), detailed = TRUE)

```

**Ejemplo:**

```r
r
CopyEdit
library(ez)
datos_largos <- pivot_longer(datos_anchos, -Instancia, names_to = "Algoritmo", values_to = "Tiempo")
ezANOVA(data = datos_largos, dv = .(Tiempo), wid = .(Instancia), within = .(Algoritmo), detailed = TRUE)

```

**InterpretaciÃ³n del resultado:**

- Si el valor p asociado al efecto principal es < Î±, se **rechaza Hâ‚€**.
- Concluimos que **al menos un tratamiento difiere en promedio**.
- Se puede realizar anÃ¡lisis post-hoc con `emmeans` para explorar las diferencias entre pares de niveles.

### ğŸ”¹ **Transformaciones de datos**

Este capÃ­tulo **no introduce nuevas pruebas estadÃ­sticas**, sino **mÃ©todos de transformaciÃ³n de variables numÃ©ricas** que **no cumplen las condiciones necesarias para pruebas paramÃ©tricas** (como normalidad o linealidad).

---

### 1. **TransformaciÃ³n lineal**

**Â¿Para quÃ© sirve?**

Para **cambiar unidades de medida** sin alterar la forma de la distribuciÃ³n (escalado o traslaciÃ³n).

**Ejemplos de estudios:**

1. Â¿La temperatura media en Santiago supera los 20 Â°C (convertida a Â°F)?
    - *Pregunta:* Â¿La temperatura media diaria en verano es mayor a 68 Â°F?
2. Â¿Un sensor de presiÃ³n calibrado en psi equivale a una media de 2 bar?
    - *Pregunta:* Â¿La presiÃ³n media registrada es igual a 2 bar?

**Condiciones:**

- Escala numÃ©rica continua
- Se conoce la relaciÃ³n entre unidades

**HipÃ³tesis:**

(No cambia la prueba estadÃ­stica, solo se transforma la escala).

**FunciÃ³n en R:**

```r
r
CopyEdit
nueva_variable <- m * original + n

```

---

### 2. **TransformaciÃ³n logarÃ­tmica**

**Â¿Para quÃ© sirve?**

Reducir la **asimetrÃ­a positiva** de una variable y acercarla a una distribuciÃ³n normal.

Utilizada antes de aplicar pruebas que requieren normalidad (t, ANOVA).

**Ejemplos de estudios:**

1. Â¿La media del logaritmo del ingreso mensual es mayor a 10?
    - *Pregunta:* Â¿El ingreso promedio, despuÃ©s de log-transformar, supera cierto umbral?
2. Â¿Los pesos de cerebros en especies animales muestran correlaciÃ³n logarÃ­tmica con el peso corporal?
    - *Pregunta:* Â¿Existe relaciÃ³n lineal entre log(peso corporal) y log(peso cerebral)?

**Condiciones:**

- Valores positivos (no se puede aplicar log a cero o negativos).
- AsimetrÃ­a positiva evidente en la variable original.

**HipÃ³tesis (ejemplo):**

- H0:Î¼logâ¡(x)=2H_0: \mu_{\log(x)} = 2H0:Î¼log(x)=2
- HA:Î¼logâ¡(x)>2H_A: \mu_{\log(x)} > 2HA:Î¼log(x)>2

**FunciÃ³n en R:**

```r
r
CopyEdit
log(x)  # o log10(x) si se quiere base 10

```

---

### 3. **Escalera de potencias de Tukey**

**Â¿Para quÃ© sirve?**

Explorar distintas potencias (Î») para transformar una variable y **aproximarla a la normalidad**.

Se usa para ajustar mejor la forma de la distribuciÃ³n o linealizar relaciones.

**Ejemplos de estudios:**

1. Â¿QuÃ© transformaciÃ³n aproxima mejor la distribuciÃ³n de la poblaciÃ³n de EE.UU. entre 1610-1850?
2. Â¿QuÃ© transformaciÃ³n permite linealizar la relaciÃ³n entre ingresos y gastos en un estudio econÃ³mico?

**Condiciones:**

- Datos numÃ©ricos y positivos
- Se busca aproximar a normalidad o mejorar relaciones funcionales

**HipÃ³tesis (implÃ­cita):**

- H0:DistribucioËŠnÂ transformadaÂ sigueÂ siendoÂ noÂ normalH_0: \text{DistribuciÃ³n transformada sigue siendo no normal}H0:DistribucioËŠnÂ transformadaÂ sigueÂ siendoÂ noÂ normal
- HA:DistribucioËŠnÂ transformadaÂ seÂ asemejaÂ aÂ normalH_A: \text{DistribuciÃ³n transformada se asemeja a normal}HA:DistribucioËŠnÂ transformadaÂ seÂ asemejaÂ aÂ normal

**FunciÃ³n en R:**

```r
r
CopyEdit
library(rcompanion)
transformTukey(x)

```

### ğŸ”¹ **Wilcoxon Signed Rank (con signo)** (CapÃ­tulo 11)

**Â¿Para quÃ© sirve?**

Comparar dos tratamientos en muestras pareadas cuando no se puede asumir normalidad.

**Ejemplos:**

1. Â¿La presiÃ³n arterial cambia tras una dieta?
2. Â¿El desempeÃ±o mejora con una nueva metodologÃ­a?

**Condiciones:**

- Muestras pareadas.
- Diferencias simÃ©tricas respecto a cero.

**HipÃ³tesis:**

- Hâ‚€: La mediana de las diferencias es cero.
- Hâ‚: La mediana difiere de cero.

**FunciÃ³n en R:**

```r
r
CopyEdit
wilcox.test(x, y, paired = TRUE)

```

| **Prueba no paramÃ©trica** | **Â¿Para quÃ© sirve?** | **Condiciones** |
| --- | --- | --- |
| **Prueba exacta de Fisher** | Evaluar asociaciÃ³n entre dos variables dicotÃ³micas en tablas 2Ã—2 | - Variables binarias  - Observaciones independientes  - Muestra pequeÃ±a o frecuencias esperadas < 5 |
| **Prueba de McNemar** | Evaluar cambios en proporciones dicotÃ³micas con datos pareados (pre/post o condiciones repetidas) | - Variable binaria  - Datos apareados  - Enfoque en discordancias |
| **Prueba Q de Cochran** | ExtensiÃ³n de McNemar para â‰¥3 tratamientos en muestras pareadas con variable dicotÃ³mica | - Variable binaria  - Muestras apareadas  - â‰¥ 3 tratamientos o condiciones |
| **Wilcoxon rank sum** | Comparar dos grupos independientes (alternativa no paramÃ©trica a t de Student independiente) | - Escala ordinal o superior  - Muestras independientes  - No requiere normalidad |
| **Wilcoxon signed rank** | Comparar dos condiciones en muestras apareadas (alternativa a t de muestras pareadas) | - Datos pareados  - Diferencias simÃ©tricas respecto a 0  - Escala ordinal o superior |